{
  "cells": [
    {
      "cell_type": "markdown",
      "source": "\n# Preprocessing Data\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "\n**In this notebook, we\u0027ll be generating our training and test data while also creating word embeddings that will be used\nfor our ML models.**",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "**Load Libraries**\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [],
      "source": "\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing import text, sequence\nimport pickle\nimport pandas as pd\nimport numpy as np\n\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "**Load Data**\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "44898\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "\nwith open(\"input/clean.txt\", \"rb\") as f:\n    text_results \u003d pickle.load(f)\n\ndataset \u003d  pd.read_csv(\"input/master_dataset.csv\")\n\nprint(len(text_results))\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "**Split Training, Validation and Test Data**\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [],
      "source": "inputs \u003d np.array(text_results)\nlabels \u003d dataset[\u0027Category\u0027]\n\nX_train, X_test,y_train, y_test \u003d train_test_split(inputs,labels, test_size\u003d0.3, random_state\u003d0)\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "**Tokenize Text and Generate Sequences**",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "**Tokenize Text**",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "outputs": [],
      "source": "max_words \u003d 10000\ntokenizer \u003d text.Tokenizer(num_words\u003dmax_words)\n# Tokenize words found in training dataset \ntokenizer.fit_on_texts(X_train)\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "**Create Sequence of Tokens**",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "outputs": [],
      "source": "X_train_sequence \u003d tokenizer.texts_to_sequences(X_train) #Transform tokens to integers\nX_test_sequence \u003d tokenizer.texts_to_sequences(X_test)\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "**Pad Sequences**\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "outputs": [],
      "source": "length \u003d 400\nX_train_padding \u003d sequence.pad_sequences(X_train_sequence,maxlen\u003dlength)\nX_test_padding \u003d sequence.pad_sequences(X_test_sequence,maxlen\u003dlength)\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "**Apply Word Embeddings - GloVE**\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "**Load Pre-trained GloVE word vectors**\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "**Important:** Please head to https://nlp.stanford.edu/projects/glove/ to download the **twitter.27B.100d** pre-trained word vectors.",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "outputs": [],
      "source": "GLOVE_WORD_VECTOR \u003d \"input/glove.twitter.27B.100d.model\"\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "**Extract Word Vectors**",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "Vocab Size in GloVE: 1193515\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "embedding_vectors \u003d {}\n\nwith open(GLOVE_WORD_VECTOR, \u0027r\u0027, encoding\u003d\u0027utf-8\u0027) as f:\n    for r in f:\n        val \u003d r.split(\u0027 \u0027)\n        word \u003d val[0]\n        weights \u003d np.asarray([float(val) for val in val[1:]])\n        embedding_vectors[word] \u003d weights\n        \nprint(\"Vocab Size in GloVE:\", len(embedding_vectors))\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "**Generate Embedding Matrix**\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "outputs": [],
      "source": "\nword_index \u003d tokenizer.word_index\nembedding_dimensions \u003d 100\n\nif max_words is not None:\n    vocabulary_length \u003d max_words\n    \nelse:\n    vocabulary_length \u003d len(word_index) + 1\n    \n    \n# Initialize Embedding Matrix With Zeros\n\nembedding_matrix \u003d np.zeros((vocabulary_length, embedding_dimensions))\n\n# Embed Matrix With Word Vectors\n\nfor word, i in word_index.items():\n    if i \u003c vocabulary_length:\n        word_vector \u003d embedding_vectors.get(word)\n        if word_vector is not None:\n            embedding_matrix[i] \u003d word_vector\n\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "**Save Training Data, Tokenizer and Embedding Matrix as Pickle Files**\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "outputs": [],
      "source": "\n# Saving our training and testing makes the data shareable and frees up resources\n\n# Save Training \u0026 Test Data\nwith open(\"input/train.pkl\", \"wb\") as f:\n    pickle.dump([X_train_padding,X_test_padding,y_train,y_test],f)\n    \n#Save Embedding Matrix    \n    \nwith open(\"input/matrix.pkl\", \"wb\") as f:\n    pickle.dump([embedding_matrix, embedding_dimensions,vocabulary_length], f)\n    \n# Saving the tokenizer avoids us having to create one from scratch every time we do inferences. \nwith open(\"input/tokenizer.pkl\", \"wb\") as file:\n    pickle.dump(tokenizer,file,protocol\u003dpickle.HIGHEST_PROTOCOL)\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "kernelspec": {
      "name": "pycharm-e8355baa",
      "language": "python",
      "display_name": "PyCharm (FakeNewsClassifier)"
    },
    "stem_cell": {
      "cell_type": "raw",
      "source": "",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}